{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from cross_validation import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=False)\n",
    "indices = np.random.permutation(len(y))\n",
    "train_percentage = 0.8\n",
    "cutoff_idx = int(train_percentage*len(y))\n",
    "y_train = y[indices[:cutoff_idx]]\n",
    "tX_train = tX[indices[:cutoff_idx]]\n",
    "y_test = y[indices[cutoff_idx:]]\n",
    "tX_test = tX[indices[cutoff_idx:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_0 =y_train.copy()\n",
    "y_train_0[y_train_0 == -1] = 0\n",
    "\n",
    "## First make a dataset where the NaNs are replaced by the mean\n",
    "tX_train_replace_invalid = tX_train.copy()\n",
    "\n",
    "# Make the -999 into NaNs\n",
    "tX_train_replace_invalid[tX_train_replace_invalid == -999.] = np.nan\n",
    "# Replace NaNs by the column average\n",
    "for i in range(tX_train.shape[1]):\n",
    "  a = tX_train_replace_invalid[:, i]\n",
    "  mean = np.average(a[ ~np.isnan(a) ])\n",
    "  a[ np.isnan(a) ] = mean\n",
    "# Now, tX_train_replace_invalid is the way we need it.\n",
    "\n",
    "## Now make a dataset where the columns with NaNs are dropped\n",
    "tX_train_drop_invalid = tX_train.copy()\n",
    "tX_train_drop_invalid = tX_train_drop_invalid[:, ~np.any(tX_train_drop_invalid == -999., axis=0)]\n",
    "# Now, tX_train_drop_invalid is the way we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_0 =y_test.copy()\n",
    "y_test_0[y_test_0 == -1] = 0\n",
    "## First make a dataset where the NaNs are replaced by the mean\n",
    "tX_test_replace_invalid = tX_test.copy()\n",
    "\n",
    "# Make the -999 into NaNs\n",
    "tX_test_replace_invalid[tX_test_replace_invalid == -999.] = np.nan\n",
    "# Replace NaNs by the column average\n",
    "for i in range(tX_test.shape[1]):\n",
    "  a = tX_test_replace_invalid[:, i]\n",
    "  mean = np.average(a[ ~np.isnan(a) ])\n",
    "  a[ np.isnan(a) ] = mean\n",
    "# Now, tX_train_replace_invalid is the way we need it.\n",
    "\n",
    "## Now make a dataset where the columns with NaNs are dropped\n",
    "tX_test_drop_invalid = tX_test.copy()\n",
    "tX_test_drop_invalid = tX_test_drop_invalid[:, ~np.any(tX_test_drop_invalid == -999., axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test_drop_invalid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 20)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 39)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 58)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 77)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 5)\n",
      "0.09265057419612496\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-8, -1, 8)\n",
    "lambdas = np.array([0])\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters=10000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_train_0, tX_train_drop_invalid, \"LEAST_SQUARE\", lambdas, gammas, degrees, K, max_iters, batch_size)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 31)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 61)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 121)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 5)\n",
      "0.09690363423462088\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-8, -1, 8)\n",
    "lambdas = np.array([0])\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters=10000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_train_0, tX_train_replace_invalid, \"LEAST_SQUARE\", lambdas, gammas, degrees, K, max_iters, batch_size)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 20)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 39)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 58)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 77)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 5)\n",
      "1.1623022202269815\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-8, -1, 8)\n",
    "lambdas = np.array([0])\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters=10000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_train_0, tX_train_drop_invalid, \"LOGISTIC_REGRESSION\", lambdas, gammas, degrees, K, max_iters, batch_size)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 31)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 61)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 121)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 6)\n",
      "1.8184817788746226\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-8, -1, 8)\n",
    "lambdas = np.array([0])\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters=10000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_train_0, tX_train_replace_invalid, \"LOGISTIC_REGRESSION\", lambdas, gammas, degrees, K, max_iters, batch_size)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 20)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 39)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 58)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 77)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 7, 5)\n",
      "0.5384875776591589\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-8, -1, 8)\n",
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters=10000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_train_0, tX_train_drop_invalid, \"REGULARIZED_LOGISTIC_REGRESSION\", lambdas, gammas, degrees, K, max_iters, batch_size)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 31)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 61)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 121)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 7, 6)\n",
      "0.6332336652916899\n"
     ]
    }
   ],
   "source": [
    "gammas = np.logspace(-8, -1, 8)\n",
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters=10000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_train_0, tX_train_replace_invalid, \"REGULARIZED_LOGISTIC_REGRESSION\", lambdas, gammas, degrees, K, max_iters, batch_size)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 20)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 39)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 58)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 77)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(200000, 96)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(200000, 115)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(200000, 134)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(200000, 153)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(200000, 172)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(200000, 191)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(200000, 210)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(200000, 229)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(200000, 248)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(9, 0)\n",
      "0.07594246565704504\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([0])\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "K=4\n",
    "max_iters=1000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_train_0, tX_train_drop_invalid, lambdas,degrees, K)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 31)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 61)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 121)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(200000, 151)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(200000, 181)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(200000, 211)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(200000, 241)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(200000, 271)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(200000, 301)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(200000, 331)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(200000, 361)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(200000, 391)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(10, 0)\n",
      "0.0690634488451319\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([0])\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "K=4\n",
    "max_iters=1000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_train_0, tX_train_replace_invalid, lambdas,degrees, K)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 20)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 39)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 58)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 77)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(200000, 96)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(200000, 115)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(200000, 134)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(200000, 153)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(200000, 172)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(200000, 191)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(200000, 210)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(200000, 229)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(200000, 248)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(12, 0)\n",
      "0.07857525875072088\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "K=4\n",
    "max_iters=1000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_train_0, tX_train_drop_invalid, lambdas,degrees, K)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(200000, 31)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(200000, 61)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(200000, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(200000, 121)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(200000, 151)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(200000, 181)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(200000, 211)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(200000, 241)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(200000, 271)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(200000, 301)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(200000, 331)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(200000, 361)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(200000, 391)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(12, 0)\n",
      "0.07108794367635787\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "K=4\n",
    "max_iters=1000\n",
    "batch_size =1\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_train_0, tX_train_replace_invalid, lambdas,degrees, K)\n",
    "\n",
    "val_error_deg_lambda_gamma = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda_gamma)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda_gamma), val_error_deg_lambda_gamma.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda_gamma[idx_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing best tuned algos on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_drop_expanded_1 = build_poly(tX_train_drop_invalid, 1)\n",
    "tx_drop_expanded_1, mean_drop_expanded_1, std_drop_expanded_1 = standardize(tx_drop_expanded_1)\n",
    "\n",
    "tx_replace_expanded_1 = build_poly(tX_train_replace_invalid, 1)\n",
    "tx_replace_expanded_1, mean_replace_expanded_1, std_replace_expanded_1 = standardize(tx_replace_expanded_1)\n",
    "\n",
    "tx_drop_expanded_10 = build_poly(tX_train_drop_invalid, 10)\n",
    "tx_drop_expanded_10, mean_drop_expanded_10, std_drop_expanded_10 = standardize(tx_drop_expanded_10)\n",
    "\n",
    "tx_replace_expanded_11 = build_poly(tX_train_replace_invalid, 11)\n",
    "tx_replace_expanded_11, mean_replace_expanded_11, std_replace_expanded_11 = standardize(tx_replace_expanded_11)\n",
    "\n",
    "tx_drop_expanded_13 = build_poly(tX_train_drop_invalid, 13)\n",
    "tx_drop_expanded_13, mean_drop_expanded_13, std_drop_expanded_13 = standardize(tx_drop_expanded_13)\n",
    "\n",
    "tx_replace_expanded_13 = build_poly(tX_train_replace_invalid, 13)\n",
    "tx_replace_expanded_13, mean_replace_expanded_13, std_replace_expanded_13 = standardize(tx_replace_expanded_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test_drop_expanded_1 = build_poly(tX_test_drop_invalid, 1)\n",
    "tx_test_drop_expanded_1 = standardize_test_data(tx_test_drop_expanded_1, mean_drop_expanded_1, std_drop_expanded_1)\n",
    "\n",
    "tx_test_replace_expanded_1 = build_poly(tX_test_replace_invalid, 1)\n",
    "tx_test_replace_expanded_1 = standardize_test_data(tx_test_replace_expanded_1, mean_replace_expanded_1, std_replace_expanded_1)\n",
    "\n",
    "tx_test_drop_expanded_10 = build_poly(tX_test_drop_invalid, 10)\n",
    "tx_test_drop_expanded_10 = standardize_test_data(tx_test_drop_expanded_10, mean_drop_expanded_10, std_drop_expanded_10)\n",
    "\n",
    "tx_test_replace_expanded_11 = build_poly(tX_test_replace_invalid, 11)\n",
    "tx_test_replace_expanded_11 = standardize_test_data(tx_test_replace_expanded_11, mean_replace_expanded_11, std_replace_expanded_11)\n",
    "\n",
    "tx_test_drop_expanded_13 = build_poly(tX_test_drop_invalid, 13)\n",
    "tx_test_drop_expanded_13 = standardize_test_data(tx_test_drop_expanded_13, mean_drop_expanded_13, std_drop_expanded_13)\n",
    "\n",
    "tx_test_replace_expanded_13 = build_poly(tX_test_replace_invalid, 13)\n",
    "tx_test_replace_expanded_13 = standardize_test_data(tx_test_replace_expanded_13, mean_replace_expanded_13, std_replace_expanded_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y, tx, w, threshold):\n",
    "    pred = tx@w\n",
    "    pred_class = [0 if p<threshold else 1 for p in pred]\n",
    "    n = len(y)\n",
    "    correct=0\n",
    "    for i in range(n):\n",
    "        if pred_class[i] == y[i]:\n",
    "            correct+=1\n",
    "    return correct/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least_squares_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((tx_drop_expanded_1.shape[1], 1))\n",
    "(w_LS_SGD_drop, _) = least_squares_SGD(y_train_0, tx_drop_expanded_1, initial_w, max_iters, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09369657599022957 0.725\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_drop_expanded_1, w_LS_SGD_drop)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_drop_expanded_1, w_LS_SGD_drop, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((tx_replace_expanded_1.shape[1], 1))\n",
    "(w_LS_SGD_replace, _) = least_squares_SGD(y_train_0, tx_replace_expanded_1, initial_w, max_iters, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09665160366953995 0.71394\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_replace_expanded_1, w_LS_SGD_replace)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_replace_expanded_1, w_LS_SGD_replace, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((tx_drop_expanded_1.shape[1], 1))\n",
    "(w_LR_SGD_drop, _) = logistic_regression(y_train_0, tx_drop_expanded_1, initial_w, max_iters, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0906950231066843 0.69176\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_drop_expanded_1, w_LR_SGD_drop)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_drop_expanded_1, w_LR_SGD_drop, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((tx_replace_expanded_1.shape[1], 1))\n",
    "(w_LR_SGD_replace, _) = logistic_regression(y_train_0, tx_replace_expanded_1, initial_w, max_iters, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.568004160537726 0.73034\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_replace_expanded_1, w_LR_SGD_replace)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_replace_expanded_1, w_LR_SGD_replace, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((tx_drop_expanded_1.shape[1], 1))\n",
    "(w_RLR_SGD_drop, _) = reg_logistic_regression(y_train_0, tx_drop_expanded_1, 0.1, initial_w, max_iters, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5317609486964952 0.69664\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_drop_expanded_1, w_RLR_SGD_drop)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_drop_expanded_1, w_RLR_SGD_drop, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((tx_replace_expanded_1.shape[1], 1))\n",
    "(w_RLR_SGD_replace, _) = reg_logistic_regression(y_train_0, tx_replace_expanded_1, 0.1, initial_w, max_iters, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6664600269995999 0.71488\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_replace_expanded_1, w_RLR_SGD_replace)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_replace_expanded_1, w_RLR_SGD_replace, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w_LS_drop, _) = least_squares(y_train_0, tx_drop_expanded_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.18749130793987 0.79022\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_drop_expanded_10, w_LS_drop)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_drop_expanded_10, w_LS_drop, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w_LS_replace, _) = least_squares(y_train_0, tx_replace_expanded_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427.85364237675833 0.81546\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_replace_expanded_11, w_LS_replace)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_replace_expanded_11, w_LS_replace, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w_RR_drop, _) = ridge_regression(y_train_0, tx_drop_expanded_13, 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.498350091411323 0.77626\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_drop_expanded_13, w_RR_drop)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_drop_expanded_13, w_RR_drop, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w_RR_replace, _) = ridge_regression(y_train_0, tx_replace_expanded_13, 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.01359636223361 0.80658\n"
     ]
    }
   ],
   "source": [
    "loss = compute_mse_loss(y_test_0.reshape(-1,1), tx_test_replace_expanded_13, w_RR_replace)\n",
    "acc = get_accuracy(y_test_0.reshape(-1,1), tx_test_replace_expanded_13, w_RR_replace, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y_test_aiCrowd, tX_test_aiCrowd, ids_test_aiCrowd = load_csv_data(DATA_TEST_PATH, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_aiCrowd_replace_invalid = tX_test_aiCrowd.copy()\n",
    "\n",
    "# Make the -999 into NaNs\n",
    "tX_test_aiCrowd_replace_invalid[tX_test_aiCrowd_replace_invalid == -999.] = np.nan\n",
    "# Replace NaNs by the column average\n",
    "for i in range(tX_train.shape[1]):\n",
    "  a = tX_test_aiCrowd_replace_invalid[:, i]\n",
    "  mean = np.average(tX_train_replace_invalid[ ~np.isnan(tX_train_replace_invalid) ])\n",
    "  a[ np.isnan(a) ] = mean\n",
    "# Now, tX_train_replace_invalid is the way we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_aiCrowd_replace_invalid_exp = build_poly(tX_test_aiCrowd_replace_invalid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_aiCrowd_replace_invalid_exp =\\\n",
    "standardize_test_data(tX_test_aiCrowd_replace_invalid_exp, mean_replace_expanded_1, std_replace_expanded_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w_LS_rep_aaaa, _) = least_squares(y_train_0, tx_replace_expanded_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = tX_test_aiCrowd_replace_invalid_exp@w_LS_rep_aaaa\n",
    "predicted_class = [-1 if p<0.5 else 1 for p in predic]\n",
    "create_csv_submission(ids_test_aiCrowd, predicted_class, \"model_replace_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
