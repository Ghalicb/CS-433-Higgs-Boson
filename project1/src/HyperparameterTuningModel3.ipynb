{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows one process of hyperparameter tuning.  \n",
    "We first prepare the datsets by first leaving 20% for testing at the end and separating the remaining 80% into 4 sets according to the categorical feature.  \n",
    "We then run grid search with 4-fold cross-validation on:  \n",
    "- Ridge regression for degree and lambda\n",
    "- Logistic regression for degree and gamma\n",
    "- Regularized logistic regression for degree, gamma and lambda\n",
    "\n",
    "Each algorithm is run on all 4 subsets of the datset.\n",
    "We then compare the three algorithms with the best parameters on the test set to decide which one is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from cross_validation import *\n",
    "from helpers import *\n",
    "from run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=False)\n",
    "seed = 1\n",
    "train_percentage = 0.8\n",
    "\n",
    "#Take 20% out for testing\n",
    "y_train, tX_train, ids_train, y_test, tX_test, ids_test = partition(y, tX, ids, train_percentage, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns with ```nan```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing train set.\n",
    "#First change y vector from {-1, 1} to {0,1}\n",
    "y_train_0 =y_train.copy()\n",
    "y_train_0[y_train_0 == -1] = 0\n",
    "\n",
    "#Drop columns with nans\n",
    "tX_train_drop_invalid = tX_train.copy()\n",
    "tX_train_drop_invalid = tX_train_drop_invalid[:, ~np.any(tX_train_drop_invalid == -999., axis=0)]\n",
    "\n",
    "##############################################################################\n",
    "#Preparing Test set\n",
    "#First change y vector from {-1, 1} to {0,1}\n",
    "y_test_0 =y_test.copy()\n",
    "y_test_0[y_test_0 == -1] = 0\n",
    "#Drop columns with nans\n",
    "tX_test_drop_invalid = tX_test.copy()\n",
    "tX_test_drop_invalid = tX_test_drop_invalid[:, ~np.any(tX_train == -999., axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate into 4 train datasets according to categorical feature\n",
    "tX_0, tX_1, tX_2, tX_3, y_0, y_1, y_2, y_3, ids_0, ids_1, ids_2, ids_3 =\\\n",
    "    separate_data(tX_train_drop_invalid, y_train_0, ids_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation with Ridge regression, Logistic regression and Regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(79874, 18)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(79874, 35)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(79874, 52)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(79874, 69)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(79874, 86)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(79874, 103)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(79874, 120)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(79874, 137)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(79874, 154)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(79874, 171)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(79874, 188)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(79874, 205)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(79874, 222)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 14\n",
      "(79874, 239)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 15\n",
      "(79874, 256)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(13, 0)\n",
      "0.059493051908617166\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
    "K=4\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_0, tX_0, lambdas,degrees, K,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(62094, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(62094, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(62094, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(62094, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(62094, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(62094, 109)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(62094, 127)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(62094, 145)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(62094, 163)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(62094, 181)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(62094, 199)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(62094, 217)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(62094, 235)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 14\n",
      "(62094, 253)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 15\n",
      "(62094, 271)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(14, 0)\n",
      "0.08189628227018213\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
    "K=4\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_1, tX_1, lambdas,degrees, K,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(40314, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(40314, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(40314, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(40314, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(40314, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(40314, 109)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(40314, 127)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(40314, 145)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(40314, 163)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(40314, 181)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(40314, 199)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(40314, 217)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(40314, 235)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(11, 0)\n",
      "0.08415136316578789\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
    "K=4\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_2, tX_2, lambdas,degrees, K,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(17718, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(17718, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(17718, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(17718, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 5\n",
      "(17718, 91)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 6\n",
      "(17718, 109)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 7\n",
      "(17718, 127)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 8\n",
      "(17718, 145)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 9\n",
      "(17718, 163)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 10\n",
      "(17718, 181)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 11\n",
      "(17718, 199)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 12\n",
      "(17718, 217)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 13\n",
      "(17718, 235)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 14\n",
      "(17718, 253)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 15\n",
      "(17718, 271)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(14, 0)\n",
      "0.0814350243920801\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
    "K=4\n",
    "training_errors, validation_errors =\\\n",
    "lambda_degree_ridge_cv(y_3, tX_3, lambdas,degrees, K,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(79923, 18)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(79923, 35)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(79923, 52)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(79923, 69)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 5)\n",
      "1.5223211012187239\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([0])\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_0, tX_0, \"LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(61985, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(61985, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(61985, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(61985, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 5)\n",
      "1.3540926797478172\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([0])\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_1, tX_1, \"LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(40333, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(40333, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(40333, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(40333, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 6)\n",
      "0.7095592721709326\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([0])\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_2, tX_2, \"LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(17759, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(17759, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(17759, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(17759, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 0, 5)\n",
      "1.0762818409576567\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([0])\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_3, tX_3, \"LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(79923, 18)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(79923, 35)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(79923, 52)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(79923, 69)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 7, 5)\n",
      "0.7322578540182074\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_0, tX_0, \"REGULARIZED_LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(61985, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(61985, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(61985, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(61985, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 7, 5)\n",
      "0.5302130309828004\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_1, tX_1, \"REGULARIZED_LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(40333, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(40333, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(40333, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(40333, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 7, 6)\n",
      "0.3186083884677893\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_2, tX_2, \"REGULARIZED_LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree = 1\n",
      "(17759, 19)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 2\n",
      "(17759, 37)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 3\n",
      "(17759, 55)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "Degree = 4\n",
      "(17759, 73)\n",
      "Fold = 1\n",
      "Fold = 2\n",
      "Fold = 3\n",
      "Fold = 4\n",
      "(0, 7, 5)\n",
      "0.5256940557782919\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -1, 8)\n",
    "gammas = np.logspace(-8, -1, 8)\n",
    "degrees = np.array([1,2,3,4])\n",
    "K=4\n",
    "max_iters = 10000\n",
    "\n",
    "training_errors, validation_errors =\\\n",
    "lambda_gamma_degree_sgd_cv(y_3, tX_3, \"REGULARIZED_LOGISTIC_REGRESSION\",lambdas, gammas, degrees, K,max_iters,1,1)\n",
    "\n",
    "val_error_deg_lambda = np.mean(validation_errors, axis=0)\n",
    "np.nanargmin(val_error_deg_lambda)\n",
    "idx_min = np.unravel_index(np.nanargmin(val_error_deg_lambda), val_error_deg_lambda.shape)\n",
    "print(idx_min)\n",
    "print(val_error_deg_lambda[idx_min])\n",
    "print(\"Best degree {}\".format(degrees[idx_min[0]]))\n",
    "print(\"Best lambda {}\".format(lambdas[idx_min[1]]))\n",
    "print(\"Best gamma {}\".format(gammas[idx_min[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create best models and compare on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand and standadrdize the 4 train sets\n",
    "tx_0_expanded, tx_1_expanded, tx_2_expanded, tx_3_expanded, means, stds =\\\n",
    "standardize_train(tX_0, tX_1, tX_2, tX_3, [14,15,12,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate into 4 test datasets and standardize them with the means and variances of the train sets\n",
    "list_tX_test, list_y_test, list_ids_test =\\\n",
    "    prepare_test(tX_test_drop_invalid, y_test_0, means, stds, ids_test,[14,15,12,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.81115118485693 0.836168084042021\n"
     ]
    }
   ],
   "source": [
    "(w_0, loss_0) = ridge_regression(y_0, tx_0_expanded, 1e-8)\n",
    "loss = compute_mse_loss(list_y_test[0].reshape(-1,1), list_tX_test[0], w_0)\n",
    "acc = get_accuracy(list_y_test[0].reshape(-1,1), list_tX_test[0], w_0, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09070264549620927 0.7625811427469632\n"
     ]
    }
   ],
   "source": [
    "(w_1, loss_1) = ridge_regression(y_1, tx_1_expanded, 1e-8)\n",
    "loss = compute_mse_loss(list_y_test[1].reshape(-1,1), list_tX_test[1], w_1)\n",
    "acc = get_accuracy(list_y_test[1].reshape(-1,1), list_tX_test[1], w_1, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10194207006528733 0.7617957395978499\n"
     ]
    }
   ],
   "source": [
    "(w_2, loss_2) = ridge_regression(y_2, tx_2_expanded, 1e-8)\n",
    "loss = compute_mse_loss(list_y_test[2].reshape(-1,1), list_tX_test[2], w_2)\n",
    "acc = get_accuracy(list_y_test[2].reshape(-1,1), list_tX_test[2], w_2, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.83312731500105 0.7661748013620885\n"
     ]
    }
   ],
   "source": [
    "(w_3, loss_3) = ridge_regression(y_3, tx_3_expanded, 1e-8)\n",
    "loss = compute_mse_loss(list_y_test[3].reshape(-1,1), list_tX_test[3], w_3)\n",
    "acc = get_accuracy(list_y_test[3].reshape(-1,1), list_tX_test[3], w_3, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [w_0, w_1, w_2, w_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100000,     -1],\n",
       "       [100000,     -1],\n",
       "       [100007,      1],\n",
       "       ...,\n",
       "       [349990,     -1],\n",
       "       [349997,     -1],\n",
       "       [349998,      1]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = predict_4sets(list_tX, list_ids, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79216\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "n_total = 0\n",
    "for i in range(len(list_tX_test)):\n",
    "    curr_pred = list_tX_test[i]@weights[i]\n",
    "    curr_predicted_class = [0 if p<0.5 else 1 for p in curr_pred]\n",
    "    n = len(list_y[i])\n",
    "    n_total += n\n",
    "    for j in range(n):\n",
    "        if curr_predicted_class[j] == list_y_test[i][j]:\n",
    "            correct+=1\n",
    "\n",
    "  \n",
    "print(\"Test accuracy {}\".format(correct/n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand and standadrdize the 4 train sets\n",
    "tx_0_expanded, tx_1_expanded, tx_2_expanded, tx_3_expanded, means, stds =\\\n",
    "standardize_train(tX_0, tX_1, tX_2, tX_3, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate into 4 test datasets and standardize them with the means and variances of the train sets\n",
    "list_tX_test, list_y_test, list_ids_test =\\\n",
    "    prepare_test(tX_test_drop_invalid, y_test_0, means, stds, ids_test, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4282561538454663 0.7838919459729865\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.ones((1, tx_0_expanded.shape[1]))\n",
    "(w_0, loss_0) = logistic_regression(y_0, tx_0_expanded, initial_w, 10000, 0.001)\n",
    "loss = compute_mse_loss(list_y_test[0].reshape(-1,1), list_tX_test[0], w_0)\n",
    "acc = get_accuracy(list_y_test[0].reshape(-1,1), list_tX_test[0], w_0, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((1, tx_1_expanded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3867306455519959 0.6719583520791824\n"
     ]
    }
   ],
   "source": [
    "(w_1, loss_1) = logistic_regression(y_1, tx_1_expanded, initial_w, 10000, 0.001)\n",
    "loss = compute_mse_loss(list_y_test[1].reshape(-1,1), list_tX_test[1], w_1)\n",
    "acc = get_accuracy(list_y_test[1].reshape(-1,1), list_tX_test[1], w_1, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.113285508398752 0.643838343619351\n"
     ]
    }
   ],
   "source": [
    "(w_2, loss_2) = logistic_regression(y_2, tx_2_expanded, initial_w, 10000, 0.001)\n",
    "loss = compute_mse_loss(list_y_test[2].reshape(-1,1), list_tX_test[2], w_2)\n",
    "acc = get_accuracy(list_y_test[2].reshape(-1,1), list_tX_test[2], w_2, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0759227820434205 0.6767309875141885\n"
     ]
    }
   ],
   "source": [
    "(w_3, loss_3) = logistic_regression(y_3, tx_3_expanded, initial_w, 10000, 0.001)\n",
    "loss = compute_mse_loss(list_y_test[3].reshape(-1,1), list_tX_test[3], w_3)\n",
    "acc = get_accuracy(list_y_test[3].reshape(-1,1), list_tX_test[3], w_3, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [w_0,w_1,w_2,w_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100000,      1],\n",
       "       [100005,     -1],\n",
       "       [100007,     -1],\n",
       "       ...,\n",
       "       [349990,     -1],\n",
       "       [349997,     -1],\n",
       "       [349998,      1]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = predict_4sets(list_tX_test, list_ids_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71148\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "n_total = 0\n",
    "for i in range(len(list_tX_test)):\n",
    "    curr_pred = list_tX_test[i]@weights[i]\n",
    "    curr_predicted_class = [0 if p<0.5 else 1 for p in curr_pred]\n",
    "    n = len(list_y[i])\n",
    "    n_total += n\n",
    "    for j in range(n):\n",
    "        if curr_predicted_class[j] == list_y_test[i][j]:\n",
    "            correct+=1\n",
    "\n",
    "  \n",
    "print(\"Test accuracy {}\".format(correct/n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand and standadrdize the 4 train sets\n",
    "tx_0_expanded, tx_1_expanded, tx_2_expanded, tx_3_expanded, means, stds =\\\n",
    "standardize_train(tX_0, tX_1, tX_2, tX_3, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate into 4 test datasets and standardize them with the means and variances of the train sets\n",
    "list_tX_test, list_y_test, list_ids_test =\\\n",
    "    prepare_test(tX_test_drop_invalid, y_test_0, means, stds, ids_test, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6864129811995152 0.7826413206603302\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.ones((1, tx_0_expanded.shape[1]))\n",
    "(w_0, loss_0) = reg_logistic_regression(y_0, tx_0_expanded, 0.1, initial_w, 10000, 0.001)\n",
    "loss = compute_mse_loss(list_y_test[0].reshape(-1,1), list_tX_test[0], w_0)\n",
    "acc = get_accuracy(list_y_test[0].reshape(-1,1), list_tX_test[0], w_0, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones((1, tx_1_expanded.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5068415467335277 0.6785783148017225\n"
     ]
    }
   ],
   "source": [
    "(w_1, loss_1) = reg_logistic_regression(y_1, tx_1_expanded, 0.1, initial_w, 10000, 0.001)\n",
    "loss = compute_mse_loss(list_y_test[1].reshape(-1,1), list_tX_test[1], w_1)\n",
    "acc = get_accuracy(list_y_test[1].reshape(-1,1), list_tX_test[1], w_1, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34919907357333063 0.6285088592474617\n"
     ]
    }
   ],
   "source": [
    "(w_2, loss_2) = reg_logistic_regression(y_2, tx_2_expanded, 0.1, initial_w, 10000, 0.01)\n",
    "loss = compute_mse_loss(list_y_test[2].reshape(-1,1), list_tX_test[2], w_2)\n",
    "acc = get_accuracy(list_y_test[2].reshape(-1,1), list_tX_test[2], w_2, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5190600039569986 0.6951191827468786\n"
     ]
    }
   ],
   "source": [
    "(w_3, loss_3) = reg_logistic_regression(y_3, tx_3_expanded, 0.1, initial_w, 10000, 0.001)\n",
    "loss = compute_mse_loss(list_y_test[3].reshape(-1,1), list_tX_test[3], w_3)\n",
    "acc = get_accuracy(list_y_test[3].reshape(-1,1), list_tX_test[3], w_3, 0.5)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100000,     -1],\n",
       "       [100005,     -1],\n",
       "       [100007,     -1],\n",
       "       ...,\n",
       "       [349990,     -1],\n",
       "       [349997,     -1],\n",
       "       [349998,      1]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [w_0,w_1,w_2,w_3]\n",
    "a = predict_4sets(list_tX_test, list_ids_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70898\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "n_total = 0\n",
    "for i in range(len(list_tX_test)):\n",
    "    curr_pred = list_tX_test[i]@weights[i]\n",
    "    curr_predicted_class = [0 if p<0.5 else 1 for p in curr_pred]\n",
    "    n = len(list_y[i])\n",
    "    n_total += n\n",
    "    for j in range(n):\n",
    "        if curr_predicted_class[j] == list_y_test[i][j]:\n",
    "            correct+=1\n",
    "\n",
    "  \n",
    "print(\"Test accuracy {}\".format(correct/n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y_test_aiCrowd, tX_test_aiCrowd, ids_test_aiCrowd = load_csv_data(DATA_TEST_PATH, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_aiCrowd_drop = tX_test_aiCrowd.copy()\n",
    "tX_test_aiCrowd_drop = tX_test_aiCrowd_drop[:, ~np.any(tX_train == -999., axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tX_test_ai, list_y_test_ai, list_ids_test_ai =\\\n",
    "    prepare_test(tX_test_aiCrowd_drop, y_test_aiCrowd, means, stds, ids_test_aiCrowd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = predict_4sets(list_tX_test_ai, list_y_test_ai, list_ids_test_ai, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(a[:,0], a[:,1], \"test_model3_co\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
